import pandas as pd
import unicodedata
import re
from typing import Optional


def preprocessar_planilha(df: pd.DataFrame) -> pd.DataFrame:
    """Limpa valores com m√∫ltiplas entradas separadas por ``|``.

    Para cada c√©lula do DataFrame, mant√©m apenas o primeiro segmento
    antes do caractere ``|`` e remove espa√ßos extras nas extremidades.

    Examples
    --------
    >>> preprocessar_planilha(pd.DataFrame({"col": ["38|40|42", "T√™nis | Adidas"]}))
        col
    0    38
    1  T√™nis

    Parameters
    ----------
    df : pd.DataFrame
        DataFrame lido da planilha original.

    Returns
    -------
    pd.DataFrame
        Novo DataFrame com os valores sanitizados.
    """

    def limpar(valor):
        if isinstance(valor, str):
            return valor.split("|")[0].strip()
        return valor

    return df.applymap(limpar)


def normalizar(texto):
    """Remove acentos, espa√ßos e pontua√ß√£o de um texto."""
    if not isinstance(texto, str):
        return ""
    texto = (
        unicodedata.normalize("NFKD", texto)
        .encode("ASCII", "ignore")
        .decode("utf-8")
        .lower()
    )
    # Remove caracteres n√£o alfanum√©ricos (espa√ßos, pontua√ß√µes, etc.)
    texto = re.sub(r"[\W_]+", "", texto)
    return texto


def normalizar_string(texto: str) -> str:
    """Normaliza strings para compara√ß√µes resilientes.

    A fun√ß√£o remove acentos, converte para min√∫sculas e elimina
    caracteres n√£o alfanum√©ricos. √â um wrapper amig√°vel em torno da
    fun√ß√£o :func:`normalizar` existente.

    Parameters
    ----------
    texto : str
        Texto de entrada que pode conter acentos ou pontua√ß√£o.

    Returns
    -------
    str
        Vers√£o sanitizada do texto.
    """

    return normalizar(texto)


def detectar_linha_cabecalho(df: pd.DataFrame, sinonimos) -> int:
    """Detecta automaticamente a linha que cont√©m os nomes das colunas.

    A heur√≠stica procura pela primeira linha que contenha pelo menos um
    dos termos esperados nos cabe√ßalhos, considerando os sin√¥nimos
    informados. Caso nenhuma linha seja encontrada, assume-se a primeira
    linha como cabe√ßalho.

    Parameters
    ----------
    df : pd.DataFrame
        DataFrame lido da planilha sem cabe√ßalho.
    sinonimos : dict
        Dicion√°rio de sin√¥nimos das colunas esperadas.

    Returns
    -------
    int
        √çndice da linha detectada como cabe√ßalho.
    """

    termos = {normalizar(chave) for chave in sinonimos.keys()}
    for nomes in sinonimos.values():
        termos.update(normalizar(n) for n in nomes)

    for idx, row in df.iterrows():
        normalizados = [normalizar(str(c)) for c in row]
        if any(c in termos for c in normalizados):
            return idx
    return 0


def inferir_coluna_por_conteudo(
    serie, n=5, nome_coluna: Optional[str] = None
) -> Optional[str]:
    """Tenta inferir o tipo da coluna analisando as primeiras N linhas.

    Parameters
    ----------
    serie : pd.Series ou DataFrame
        Coluna a ser analisada. DataFrames devem possuir apenas uma
        coluna, caso contr√°rio um ``TypeError`` ser√° levantado.
    n : int, optional
        N√∫mero de linhas utilizadas para a infer√™ncia.

    As heur√≠sticas levam em considera√ß√£o:

    - ``produto``: presen√ßa de marcas conhecidas em texto;
    - ``tamanho``: inteiros entre 15 e 50;
    - ``quantidade``: inteiros entre 1 e 100;
    - ``preco_unitario/preco_total``: valores contendo ``","`` ou ``".``.
    - Detec√ß√£o por nome da coluna para colunas principais, opcionais e
      irrelevantes.
    """

    if isinstance(serie, pd.DataFrame):
        if serie.shape[1] != 1:
            raise TypeError("'serie' deve ser uma Series ou DataFrame de uma √∫nica coluna")
        serie = serie.iloc[:, 0]
    if not isinstance(serie, pd.Series):
        raise TypeError("'serie' deve ser uma Series")

    nome_normalizado = normalizar_string(nome_coluna) if nome_coluna else ""
    principais = {"descricao", "nome", "item", "produto"}
    opcionais = {"modelo", "tamanho", "categoria", "subcategoria"}
    irrelevantes = {
        "codigoml",
        "sku",
        "quantidade",
        "endereco",
        "grade",
        "seller",
        "valor",
        "total",
        "vertical",
        "typeseller",
    }

    if any(chave in nome_normalizado for chave in irrelevantes):
        return None
    for chave in principais:
        if chave in nome_normalizado:
            return "produto"
    for chave in opcionais:
        if chave in nome_normalizado:
            return chave

    amostra = serie.dropna().astype(str).head(n).str.lower()
    if amostra.empty:
        return None

    texto = " ".join(amostra)
    produto_keywords = [
        "nike",
        "adidas",
        "tenis",
        "t√™nis",
        "sapato",
        "camisa",
        "calca",
        "cal√ßa",
    ]
    if any(k in texto for k in produto_keywords):
        return "produto"

    numeros = (
        amostra.str.replace(",", ".", regex=False)
        .str.extract(r"(-?\d+\.?\d*)")[0]
    )
    numeros = pd.to_numeric(numeros, errors="coerce")
    if numeros.notna().all():
        if (numeros % 1 == 0).all() and numeros.between(15, 50).all():
            return "tamanho"
        if (numeros % 1 == 0).all() and numeros.between(0, 99).all():
            return "quantidade"

    if amostra.str.contains(r"[,.]").all():
        return "preco_unitario"

    return None


def inferir_seguro(df: pd.DataFrame, coluna, n=5) -> Optional[str]:
    """Obt√©m coluna de forma resiliente e delega para ``inferir_coluna_por_conteudo``.

    Garante que ``coluna`` seja um nome v√°lido do ``DataFrame`` e lida com
    casos de nomes duplicados ou colunas n√£o encontradas. Nomes iniciados
    por ``Unnamed`` s√£o ignorados.
    """
    nome = str(coluna).strip()
    if nome.lower().startswith("unnamed"):
        return None

    serie = df.get(nome)
    if serie is None:
        return None
    if isinstance(serie, pd.DataFrame):
        if serie.shape[1] == 0:
            return None
        serie = serie.iloc[:, 0]

    return inferir_coluna_por_conteudo(serie, n=n, nome_coluna=nome)


def encontrar_colunas_necessarias(caminho_arquivo: str):
    """Carrega a planilha e detecta as colunas relevantes.

    A fun√ß√£o procura por uma coluna de descri√ß√£o do produto aceitando
    varia√ß√µes como ``produto``, ``item`` ou ``descri√ß√£o``. Colunas
    opcionais (``modelo``, ``tamanho``, ``categoria`` e ``subcategoria``)
    s√£o utilizadas se estiverem presentes, enquanto colunas irrelevantes
    como ``sku`` ou ``quantidade`` s√£o ignoradas. Todas as an√°lises s√£o
    realizadas de maneira case-insensitive e sem acentua√ß√£o para garantir
    robustez contra planilhas com nomes diferentes.

    Parameters
    ----------
    caminho_arquivo : str
        Caminho para o arquivo Excel a ser analisado.

    Returns
    -------
    tuple
        ``(df, aba, info)`` onde ``df`` √© o DataFrame sanitizado da aba
        analisada, ``aba`` √© o nome da aba utilizada e ``info`` √© um
        dicion√°rio contendo:

        ``principal`` : nome da coluna de descri√ß√£o do produto
        ``extras`` : lista de colunas opcionais aproveitadas
        ``ignoradas`` : lista de colunas irrelevantes identificadas

    Raises
    ------
    ValueError
        Se nenhuma coluna de descri√ß√£o do produto for encontrada em
        nenhuma aba do arquivo.
    """

    obrigatorias = [
        "produto",
        "item",
        "nome",
        "descri√ß√£o",
        "descri√ß√£o do item",
    ]
    opcionais = ["modelo", "tamanho", "categoria", "subcategoria"]
    irrelevantes = [
        "quantidade",
        "qtd",
        "qtde",
        "c√≥digo ml",
        "codigo ml",
        "sku",
        "valor unit",
        "valor unitario",
        "pre√ßo unitario",
        "preco unitario",
        "valor total",
        "pre√ßo total",
        "preco total",
        "valor",
        "total",
        "vertical",
        "type seller",
        "endere√ßo",
        "grade",
    ]

    # sin√¥nimos m√≠nimos para detec√ß√£o da linha de cabe√ßalho
    sinonimos_cabecalho = {"produto": obrigatorias}
    for opc in opcionais:
        sinonimos_cabecalho[opc] = [opc]

    xls = pd.ExcelFile(caminho_arquivo)
    for aba in xls.sheet_names:
        df_raw = pd.read_excel(xls, sheet_name=aba, header=None)
        linha_cabecalho = detectar_linha_cabecalho(df_raw, sinonimos_cabecalho)
        df = df_raw.iloc[linha_cabecalho + 1 :].copy()
        df.columns = df_raw.iloc[linha_cabecalho].fillna("").astype(str).str.strip()
        df = preprocessar_planilha(df)

        colunas_norm = {col: normalizar_string(col) for col in df.columns}

        # coluna principal
        obrig_norm = [normalizar_string(c) for c in obrigatorias]
        principal = None
        for original, norm in colunas_norm.items():
            if any(chave in norm for chave in obrig_norm):
                principal = original
                break
        if principal is None:
            continue

        # opcionais
        opcionais_norm = [normalizar_string(c) for c in opcionais]
        extras = []
        for original, norm in colunas_norm.items():
            if original == principal:
                continue
            if any(chave in norm for chave in opcionais_norm):
                extras.append(original)

        # irrelevantes
        irrelevantes_norm = [normalizar_string(c) for c in irrelevantes]
        ignoradas = []
        for original, norm in colunas_norm.items():
            if any(chave in norm for chave in irrelevantes_norm):
                ignoradas.append(original)

        extras_msg = ", ".join(extras) if extras else "nenhuma"
        ignoradas_msg = ", ".join(ignoradas) if ignoradas else "nenhuma"
        print(f"‚úî Coluna principal identificada: {principal}")
        print(f"‚ûï Colunas extras inclu√≠das: {extras_msg}")
        print(f"üö´ Colunas ignoradas: {ignoradas_msg}")

        info = {"principal": principal, "extras": extras, "ignoradas": ignoradas}
        return df, aba, info

    raise ValueError("Nenhuma coluna de descri√ß√£o do produto foi encontrada.")


def identificar_colunas_busca(df: pd.DataFrame):
    """Identifica colunas relevantes para montagem da frase de busca.

    A fun√ß√£o aceita diferentes nomes para a coluna principal de
    descri√ß√£o (``produto``, ``item``, ``nome``, ``descri√ß√£o`` ou
    ``descri√ß√£o do item``). Outras colunas como ``modelo``, ``tamanho``,
    ``categoria`` e ``subcategoria`` s√£o utilizadas apenas se estiverem
    presentes. Colunas consideradas irrelevantes, como ``quantidade`` ou
    ``sku``, s√£o listadas e ignoradas automaticamente. Os nomes das
    colunas s√£o comparados de forma case-insensitive e sem acentua√ß√£o.

    Parameters
    ----------
    df : pd.DataFrame
        DataFrame com os dados da planilha original.

    Returns
    -------
    tuple
        (coluna_principal, colunas_opcionais, colunas_ignoradas)
    """

    # sin√¥nimos aceitos para a coluna principal de descri√ß√£o
    obrigatorias = [
        "produto",
        "item",
        "nome",
        "descri√ß√£o",
        "descri√ß√£o do item",
    ]

    # colunas que enriquecem a busca quando dispon√≠veis
    opcionais = ["modelo", "tamanho", "categoria", "subcategoria"]

    # colunas que n√£o devem ser consideradas durante a busca
    irrelevantes = [
        "quantidade",
        "c√≥digo ml",
        "sku",
        "endere√ßo",
        "grade",
        "valor unit",
        "preco unitario",
        "valor total",
        "preco total",
        "vertical",
        "type seller",
    ]

    # Normaliza nomes das colunas
    colunas_norm = {col: normalizar_string(col) for col in df.columns}

    # Identifica coluna principal
    obrigatorias_norm = [normalizar_string(k) for k in obrigatorias]
    coluna_principal = None
    for original, norm in colunas_norm.items():
        if any(chave in norm for chave in obrigatorias_norm):
            coluna_principal = original
            break
    if coluna_principal is None:
        raise ValueError("Nenhuma coluna de descri√ß√£o do produto foi encontrada.")

    # Colunas opcionais
    opcionais_norm = [normalizar_string(k) for k in opcionais]
    colunas_opcionais = []
    for original, norm in colunas_norm.items():
        if original == coluna_principal:
            continue
        if any(chave in norm for chave in opcionais_norm):
            colunas_opcionais.append(original)

    # Colunas irrelevantes
    irrelevantes_norm = [normalizar_string(k) for k in irrelevantes]
    colunas_ignoradas = []
    for original, norm in colunas_norm.items():
        if any(chave in norm for chave in irrelevantes_norm):
            colunas_ignoradas.append(original)

    extras_msg = ", ".join(colunas_opcionais) if colunas_opcionais else "nenhuma"
    ignoradas_msg = ", ".join(colunas_ignoradas) if colunas_ignoradas else "nenhuma"
    print(f"‚úî Coluna principal identificada: {coluna_principal}")
    print(f"‚ûï Colunas extras inclu√≠das: {extras_msg}")
    print(f"üö´ Colunas ignoradas: {ignoradas_msg}")

    return coluna_principal, colunas_opcionais, colunas_ignoradas


def montar_frase_busca(row: pd.Series, coluna_principal: str, colunas_opcionais):
    """Constr√≥i a frase de busca a partir das colunas relevantes.

    Parameters
    ----------
    row : pd.Series
        Linha da planilha com os dados do produto.
    coluna_principal : str
        Nome da coluna de descri√ß√£o do item.
    colunas_opcionais : list
        Lista de colunas adicionais a serem consideradas.

    Returns
    -------
    str
        Frase pronta para a busca.
    """

    partes = [str(row.get(coluna_principal, "")).strip()]
    for coluna in colunas_opcionais:
        valor = row.get(coluna)
        if pd.notna(valor) and str(valor).strip():
            partes.append(str(valor).strip())
    return " ".join(partes).strip()
